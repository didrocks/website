First step of getting the ubuntu desktop bullet proof

ZFS changes in 20.04 LTS
- still experimental
- ZFS 0.8.3
- new installation
- changes in term of features (pools upgraded to 5000)
- preventing upgrading bpool
- perf enhancements (grub for instance: from 80s to immediate for 100 system snapshots). we had to come with creative strategy for that one :p
- more robust boot
- a lot of bug fixes (for instance, we don’t export your existing pools)
- zsys by defaults

-----

Zsys
What is zsys?
- boot env
- ligthweight: only run on demand (socket activated). Permissions are handled via polkit (a separate chapter on that). No local DB, all data are set on the ZFS datasets (a separate chapter on that too)
Features:
* zsysctl/zsysd (shell completion) or man page for every commands and subcommands. Those are autogenerated and should always be up to date. option completion.
(you can as well prepend with help any command/subcommands, for instance: zsysctl help completion)
A good way of contributing is to expand their comments -> github
zsysctl list (alias for zsysctl machine list)
- integration with apt, case of do-release-upgrade to create system state save
- automated cron-based user snapshots
- You can revert in grub (next chapter about state management):
 * non destructive (don’t destroy intermediate snapshots). You can revert the revert
 * When reverting, we don’t only revert, but reapply exactly the same properties (stored when doing the snapshots) and even with the exact same kernel version your successfully booted on! If that kernel can’t be found anymore for whatever reason (you have a persistent/boot), we default to latest available kernel for that snapshot.
- create datasets for each user with gnome-control-center, adduser, useradd and handling modification for usermod. There is still the opened case for userdel.
- fast boot via zfs generator (zsys out of the way)
- committing your successful boot. If can’t boot -> reboot on the older good old version
- GC (will be detailed in a separate chapter)
- multiple machines
- strongly tested (hundreds of tests + some integration tests for grub)
- for any bug, please follow the instructions on github issue (and report the content with apport which collects a lot of debugging info we will need)

------
Interacting with zsys: state management
<- why using state instead of snapshots? -> avoid confusing administrators >
Also the previous is different from pure ZFS:
 * non destructive (don’t destroy intermediate snapshots). You can revert the revert
 * When reverting, we don’t only revert, but reapply exactly the same properties (stored when doing the snapshots) and even with the exact same kernel version your successfully booted on! If that kernel can’t be
 found anymore for whatever reason (you have a persistent/boot), we default to latest available kernel for that snapshot.
zsysctl show (alias for zsysctl machine show)
      -- full
zsysctl save (named snapshots) (alias for zsysctl state save)
    --system
-> grub impact on named system vs non system snapshot. Cloned system names
zsysctl remove (user)
   --system
Normally, it’s a command you don’t have to run yourself thanks to GC.
-> all users + case of deps
+ short names: snapshot name (if unique in that space), dataset suffix, dataset name or full path.
show cases with removal without confirmation, with confirmation, skipping confirmation…
/!\ shared user states:
rpool/USERDATA/root_bxalkc-rpool.ROOT.ubuntu-ubuntu-5pacof
rpool/USERDATA/root_bxalkc-rpool.ROOT.ubuntu-2zhm07
-> it will only unlink with one state (the user state won’t be fully removed).
it will then back to a normal names: rpool/USERDATA/root_bxalkc. More information on the dataset layout and links between user and system datasets in a future post.
- reverting in grub
   -> system only or system + all users
We took care so that it’s easily editable by users (used of functions but with readables names). We didn’t use that function for normal boots or advanced options to not confuse advanced users.
grub message:
revert to previous release, with %s on %s
This doesn’t destroy intermediate snapshots (contrary to a zfs rollback), you can revert the revert! Even the userdata if you choose to keep them separated!
* user state:
we have plan for later, but now, only available via .zfs/

---------
Other zsys features
* verbosity: client/service architecture, you can change the loglevel for the daemon (dropping to the journal) with zsysctl service loglevel.
You can stream in real time the verbose information for each request, and only for the current request with -v, -vv
* zsysctl service commands:
more internals: dump for logs internal state, force a gc collection, change temporary loglevel, force an internal refresh of zfs state, reload the daemon, ping for its status, stop it or activate temporarly the traces (type GCU and more) with examples
* There are some other hidden commands (they will shell complete subcommands if you press them) which are more for system and debug purposes. If you are interested, they are listed on the autogenerated README on github.
Any help on getting better log level, blabla, good way to contribute.
* Handling permissions polkit

* More information on how this all ties up:
* apt integration: apt hook (/etc…)
* hourly connected user snapshots (systemctl…)
(socket activated systemctl status .socket and .service)
* hourly GC service


----
GC
Why we need a GC
Runs once a day
Complex setup, because we have clones and snapshots on those clones, so we have dependencies (snapshots depending on clones depending on snapshots)
GC policy: default. This is tweakable by dropping a file in … which is the following (copying the files).
It means:
keep N amount of snapshots at least
keeping all snapshots for the past %s days

This is valid for users and systems snapshots (cleaning system snapshots first, and then fullfilling the dependencies on users)
Try to space evenly as much as possible snapshots (however, some have to be kept)
it’s keeping (at least)
If you want to force removing a snapshots, you have the zsysctl state remove command (with its dependencies).

-----
/!\ basic ZFS knowledge (like what is a datasets is expected starting from here <link to youtube video>
Why this dataset layout?
Partitions:
grub in EFI, ubuntu always creates now an EFI partition.
- Why grub in a fixed partition?
-> case of revert, if we revert grub (we revert the menu, but don’t update the dataset with install-grub and end up in limbo pointing the the previous grub installation and content)
- separate swap partition (what we learned enabling swap in zfs pool in previous release)
- separate bpool -> less features to be readable by grub than rpool. However, it’s versionned similarly than rpool and contents all kernels
- rpool with multiple types of datasets

3 kinds of datasets:
- system datasets: rpool/ROOT/ubuntu_autogenerated + bpool/ equivalent
- user datasets: rpool/USERDATA/user_autogenerated
- persistent datasets: no state saved, always shared even if you revert.
-> not, rpool aren’t hardcoded. also USERDATA can be in any imported pool. USERS can even be distributed in multiple pools (but why would you do that?)

-> By default on desktop:
- <layout>

Why this layout, to allow people to have this kind of layout, like the one we could set on server:
- <layout 2>
-> keep database like mysql persistent
-> keep docker persistent
and so on…
while have apt, and other data linked to a system sets part of system datasets.

We will provide a command in the future to transition to this kind of datasets. For now, advanced users can do that with zfs rename.

Technically: separate bpool isn’t mandatory if you don’t enable features incompatbile with grub (and booting from a snapshot). So, if you have a manual layout, you can do that yourself,

So, we ends up with:
Challenge: /boot/grub mounts before zfs-mount.service is actived.
-> use of zfs mount generator (out of the way for non revert) create our .mount for all imported pools.
We prevent the initramfs to mount all datasets in rpool/ROOT -> indeed, /var/lib is maybe persistent, do that in the generator as well.

-> /etc/fstab for efi and grub

* If you want to edit the default layout:
-> zsys-setup in ubiquity
Note: this is where people can also change their default installations and pool options. Do this with care though as some feature can break your installation! (for instance, the bpool features have been carefully picked to not break booking from grub, including when picking a snapshot)

-----------
Deep dive in zsys properties
* the generator
zpool import cache
create cache files
(generator is enabled at installation time by … symlink)
* zsys properties on system.
LastUsed (using snapshot times for snapshots)
Bootfs -> cloned and mounted datasets in initramfs only (for not mounting rpool/ROOT/…/var/lib children before optional persistent rpool/var/lib is mounted)
LastBooted kernel
user datasets: BootfsDatasets com.ubuntu.zsys:bootfs-datasets (linked to multiple datasets)
We store on snapshots the property as they were when snapshotted! We also track the local or inherited properties to that we only rebuild and reset correct local property when reverting

The link is on snapshot names for snapshots.
show snapshot properties

-----------
Convert from 18.04 with ZFS on root following this guide to zsys compatible

-----------
Future work and enhancements
Next cycle:
Future cycles:
